# Distributed-Convex-Relaxation-for-Task-Replication
Centralized and distributed algorithms by integrating convex optimization and approximation method, which achieves effective solution with high accuracy in fast convergence and adapt to different network scales, respectively.

import winsound
import datetime
import numpy as np
import scipy.special


Just change the parameter N in the code for different task scale, Fm or Pm for different server performance, and tau for different threshold constraints. Other parameters are modified in the experiment section of the paper.
